#! /usr/bin/env python3
import os
import sys
import yaml
import logging
import re
import operator
import boto3
import urllib

import xml.etree.ElementTree as ET
import urllib.request

import json

def main():
    all_written_feeds = []
    logging.basicConfig(encoding='utf-8', level=logging.INFO)
    if 'LOGLEVEL' in os.environ:
        logging.getLogger().setLevel(os.environ['FF_LOGLEVEL'])

    config_file = './feeds.yaml'
    if 'FF_CONFIG_FILE' in os.environ:
        config_file = os.environ['FF_CONFIG_FILE']

    if 'FF_CONFIG_FILE_S3_BUCKET' in os.environ:
        config_file = '/tmp/feeds.yaml'
        bucket = os.environ['FF_CONFIG_FILE_S3_BUCKET']
        object = os.environ['FF_CONFIG_FILE_S3_OBJECT_NAME']
        s3 = boto3.client('s3')
        s3.download_file(bucket, object, config_file)

    config = {}
    with open(config_file, "r") as file:
        try:
            config = yaml.safe_load(file)
        except yaml.YAMLError as err:
            print(err)

    # It looks like sys.argv doesn't exist under Lambda
    if sys.argv:
        sys.argv.pop(0)
    for feed in config['feeds']:
        if sys.argv:
            if feed['name'] not in sys.argv:
                logging.info(f"Skipping feed '{feed['name']}'; not passed as an argument")
                continue
        logging.info(f"Processing feed '{feed['name']}' from '{feed['feed_url']}'")

        root = filter_rss_feed( feed )
        if 'merge_in' in feed:
            logging.debug(f"Merging")
            for url in feed['merge_in']:
                logging.debug(f"Merging in feed from '{url}'")
                merge_rss = ET.fromstring(download_rss_file(url))
            root = merge_feeds(merge_rss, root)

        rss = ET.tostring(root, encoding='unicode', method='xml')
        written_feeds = write_feed(feed, rss)
        all_written_feeds.append( written_feeds )


    print("Wrote feeds:")
    for feed in all_written_feeds:
      print(feed[0])
      for location in feed[1]:
        print(f"  {location}")


# Merge source's episodes into dest's channel
# both should be ET objects
def merge_feeds(source, dest):
    #TODO: sort the items, though so far it seems podcast apps are happy to do that for me
    dest_channel = dest.find('channel')
    for item in source.iter(tag='item'):
        episode = get_episode_tags(item)
        if 'pubDate' in episode:
            logging.debug(f"Merging in '{episode['title']}' from '{episode['pubDate']}'")
            dest_channel.append(item)

    return dest

# Given a feed (a hash from the feeds.yaml file), downloads the RSS and uses
# ElementTree to be able to modify it.
# Then applies fiddles (which are feed-wide) and filters (which operate per-episode)
# Returns the ET representation of the feed
def filter_rss_feed(feed):
    rss = download_rss_file(feed['feed_url'])
    root = ET.fromstring(rss)

    if 'fiddles' in feed:
        for fiddle in feed['fiddles']:
            fiddle_dispatch[fiddle['fiddle']]( root, fiddle['config'])

    # An 'item' is an episode in a 'channel' which is what you'd think of as a 'feed'
    channel = root.find('channel')
    for item in root.iter(tag='item'):
        episode = get_episode_tags(item)
        logging.debug(f"Starting {episode['guid']} {episode['title']}")
        # A filter function returns 0 if it wants to remove the episode, 1 if it wants
        # to remove it. Default to keep
        if 'filters' in feed:
            keep = 1
            for filter in feed['filters']:
                keep = filter_dispatch[filter['filter']]( episode, filter['config'] )
                if keep < 1:
                    channel.remove(item)

    return root

def get_episode_tags(item):
    episode = {}
    for field in item.findall('./'):
        tag=re.sub('{\S+}', '', field.tag)
        #TODO: Figure out what's going on here (rhlstp breaks it)
        #if tag in episode:
        #   logging.error(f"Tag '{tag}' already defined (as '{episode['tag']}') in feed")
        episode[tag] = field.text
    return episode

# Filter out episodes that are too short. This was triggered by the More or Less
# podcast where the World Service programme is a ~9min excerpt from the Radio 4
# one, and both are on the same feed
#
# Expects a threshold key in the config, one of 'minutes', 'seconds' or 'hours', and
# an operator (lessThan, lessThanOrEqualTo, etc.) to use to compare the duration with
# the threshold
def filter_duration(episode, config):

    duration_filter_seconds = -1
    if 'seconds' in config:
      duration_filter_seconds = int(config['seconds'])
    elif 'minutes' in config:
      duration_filter_seconds = int(config['minutes']) * 60
    elif 'hours' in config:
      duration_filter_seconds = int(config['hours']) * 60 * 60

    if duration_filter_seconds < 0:
        logging.error("Could not parse duration out of value; aborting filter")
        logging.error(f"Value: {config}")
        return 1

    operators = {
        'lessThan':             operator.lt,
        'lessThanOrEqualTo':    operator.le,
        'greaterThan':          operator.gt,
        'greaterThanOrEqualTo': operator.ge,
        'equalTo':              operator.eq,
        'notEqualTo':           operator.ne,
    }
    if not config['operator'] in operators:
        logging.error(f"Invalid operator '{config['operator']}")


    #TODO: Find other ways duration might be encoded
    if 'duration' in episode:
        episode_duration = int(episode['duration'])
        if operators[config['operator']]( episode_duration , duration_filter_seconds):
            logging.debug(f"  Filtering out; duration of '{episode['duration']}' is {config['operator']} filter threshold of '{duration_filter_seconds}'")
            return 0
        else:
            logging.debug(f"  Retaining; duration of '{episode['duration']}' is not {config['operator']} filter threshold of '{duration_filter_seconds}'")
    else:
        logging.debug(f"Retaining '{episode['title']}'; it has no 'itunes duration' field");
        return 0


    return 1

# Filter out episodes with particular phrases in the fields. This was triggered by a
# few series doing a set of 'Book Club' episodes that are all about books I haven't read
#
# Config should have two keys, a 'pattern', and a 'field' to apply it to, and optionally
# a 'case_insensitive' which, if set, will cause the match to be case-insensitive
def filter_regex(episode, config):
    logging.debug(f"Running regex_exclude filter on '{episode['title']}' with config '{config}'")

    field_name = config['field']
    pattern = config['pattern']
    action = config['action']

    if not field_name in episode:
        logging.debug(f"Retaining '{episode['title']}'; it has no '{field_name}' field to match against")

    episode_matches = 0;

    if config['action'] == 'include':
        if re.search( pattern, episode[field_name] ):
            logging.debug(f"Retaining '{episode['title']}'; field '{field_name}' matches pattern '{pattern}'");
            return 1
        else:
            logging.debug(f"Filtering out '{episode['title']}'; field '{field_name}' does not match pattern '{pattern}'");
            return 0
    elif config['action'] == 'exclude':
        if re.search( pattern, episode[field_name] ):
            logging.debug(f"Filtering out '{episode['title']}'; field '{field_name}' matches pattern '{pattern}'");
            return 0
        else:
            logging.debug(f"Retaining '{episode['title']}'; field '{field_name}' does not match pattern '{pattern}'");
            return 1
    else:
        logging.error(f"Action '{config['action']}' invalid; must be either 'include' or 'exclude'")

    return 1

filter_dispatch = {
    'regex': filter_regex,
    'duration': filter_duration
}

# Testing this got confusing quickly as the new feeds had the same name, so
# this fiddle allows for changing the title
def fiddle_append_to_title(feed, config):
    logging.info(f"Appending '{config['string']}' to title")
    title = feed.find('channel/title')
    new_title = (f"{title.text} {config['string']}")
    title.text = new_title

    imagetitle = feed.find('channel/image/title')
    if imagetitle:
        new_title = (f"{imagetitle.text} {config['string']}")
        imagetitle.text = new_title

def fiddle_replace_title(feed, config):
    logging.info(f"Setting title to '{config['string']}'")
    title = feed.find('channel/title')
    title.text = config['string']

# Similarly, a new image might be useful!
def fiddle_replace_feed_image(feed, config):
    logging.info(f"Editing image to '{config['url']}'")
    image_url = feed.find('channel/image/url')
    if image_url:
        image_url.text = config['url']
    #TODO: Fixup images defined in other ways (like se2kb)

fiddle_dispatch = {
    'append_to_title': fiddle_append_to_title,
    'replace_title' : fiddle_replace_title,
    'replace_feed_image': fiddle_replace_feed_image
}

# # #
# #
#


def upload_file_s3(content, config):
    bucket_name = config['bucket']
    object_name = config['object']
    logging.info(f"S3 upload: writing object '{object_name}' to bucket '{bucket_name}'")
    s3 = boto3.resource('s3')
    s3.Object(bucket_name, object_name).put(Body=content, ContentType='application/rss+xml')

    region = boto3.client('s3').get_bucket_location(Bucket=bucket_name)['LocationConstraint']
    url="https://" + bucket_name + ".s3." + region + ".amazonaws.com/" + object_name;

    return url

def download_rss_file(url):
    content = download_file(url)
    if content.startswith('<html') or content.startswith('<!doctype html>'):
        logging.error('Tried to download an RSS file, got HTML, from ' + url)
    return content

def download_file(url):
    logging.debug(f"Downloading {url}")
    response = urllib.request.urlopen(url)
    data = response.read();
    content = data.decode('utf-8')
    return content

def write_feed(feed, rss):
    written_feeds=[]
    if 'FF_NO_WRITE_FEED' in os.environ:
        logging.info("FF_NO_WRITE_FEED set; not writing feed")
        return
    if 'FF_FEED_TO_STDOUT' in os.environ:
        logging.info("FF_FEED_TO_STDOUT set; writing feed to stdout")
        print(rss)
        return
    if 'file' in feed['output']:
        if 'FF_IS_LAMBDA' in os.environ:
            logging.info('Running as lambda; skipping `file` options and writing nothin glocally')
        else:
            logging.info(f"Writing output feed to '{feed['output']['file']['path']}'")
            with open(feed['output']['file']['path'], "w") as f:
                print(rss, file=f)
            written_feeds.append(feed['output']['file']['path'])

    if 's3' in feed['output']:
        url=upload_file_s3(rss, feed['output']['s3'])
        written_feeds.append(url)

    return [feed['name'], written_feeds]

def lambda_handler(event, context):
    main()

main()
